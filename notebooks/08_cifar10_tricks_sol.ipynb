{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "08_cifar10_tricks_sol",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tbTYFRhJoaBu"
      },
      "source": [
        "# Cifar10 classification with and without normalization\n",
        "\n",
        "In this notebook you will download the cifar10 dataset which contains quite small images (32x32x3) of 10 classes. The data is from the Canadian Institute For Advanced Research. You will plot examples of the images with the class label. Note that because the images are so small it's not always very easy to recoginse which of the ten classes is on the iamge, even as a human. After loading the dataset you will train multiple models and compare the performances of the models on the testset.\n",
        "\n",
        "**Dataset:**  You work with the Cifar10 dataset. You have 60'000 32x32 pixel color images of 10 classes (\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\")\n",
        "\n",
        "**Content:**\n",
        "* load the original cifar10 data create a train val and test dataset\n",
        "* visualize samples of cifar10 dataset\n",
        "* train a random forest on the pixelvalues\n",
        "* train a random forest on the vgg16 features of the images\n",
        "* use transfer learning with the pretrained vgg16 network\n",
        "* train a cnn from scratch\n",
        "* train a cnn from scratch with dropout\n",
        "* train a cnn from scratch with batchnorm\n",
        "* train a cnn from scratch with data augmentation\n",
        "* compare the performances of the models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PEIS4WvpsT5t"
      },
      "source": [
        "#### Imports\n",
        "\n",
        "In the next two cells, we load all the required libraries and functions. We download the Mnist data, normalize the pixelvalues to be between 0 and 1, and seperate it into a training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "scrolled": true,
        "id": "-0u353ydb9w2",
        "colab": {}
      },
      "source": [
        "# load required libraries:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "plt.style.use('default')\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten , Activation, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7kfDCYsxRVJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Load and plot the data\n",
        "\n",
        "In the next cell you will load the Cifar10 dataset, 50'000 images are in the training set and 10'000 are in the test dataset. You will use 10'000 for the train and validation dataset.\n",
        "You will plot one random example of each label and will see\n",
        "that the images are really small and finally you can convert the lables into the one hot encoding.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRLfhCzVviwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4zwRlaILb9xF",
        "colab": {}
      },
      "source": [
        "# separate train val and test dataset\n",
        "X_train=x_train[0:10000] \n",
        "Y_train=to_categorical(y_train[0:10000],10) # one-hot encoding\n",
        "\n",
        "X_val=x_train[20000:30000] \n",
        "Y_val=to_categorical(y_train[20000:30000],10)\n",
        "\n",
        "X_test=x_test \n",
        "Y_test=to_categorical(y_test,10)\n",
        "\n",
        "del x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o6jukEcMb9xL",
        "colab": {}
      },
      "source": [
        "labels=np.array([\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"])\n",
        "#sample image of each label\n",
        "plt.figure(figsize=(15,15))\n",
        "for i in range(0,len(np.unique(np.argmax(Y_train,axis=1)))):\n",
        "    rmd=np.random.choice(np.where(np.argmax(Y_train,axis=1)==i)[0],1)\n",
        "    plt.subplot(1,10,i+1)\n",
        "    img=X_train[rmd]\n",
        "    plt.imshow(img[0,:,:,:])\n",
        "    plt.title(labels[i]+\" \"+np.str(np.argmax(Y_train,axis=1)[rmd][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OLX7w_4Zb9xP",
        "colab": {}
      },
      "source": [
        "# check the shape of the data\n",
        "X_train.shape,Y_train.shape,X_val.shape,Y_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EAsMG-WcKms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalization\n",
        "X_train = X_train/255\n",
        "X_val = X_val/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5rxBKcRdPKR",
        "colab_type": "text"
      },
      "source": [
        "### RF on pixelvalues\n",
        "In this section you will train a random forest on the raw pixelvalues of the images.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gQnu_hIpcUp1",
        "colab": {}
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=40,random_state=22)\n",
        "clf.fit(X_train.reshape(len(X_train),32*32*3), np.argmax(Y_train,axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kY9AkXRrcUp-",
        "colab": {}
      },
      "source": [
        "pred=clf.predict(X_test.reshape(len(X_test),32*32*3))\n",
        "acc=np.average(pred==np.argmax(Y_test,axis=1))\n",
        "res1 = pd.DataFrame(\n",
        "          {'Acc' : acc}, index=['rf on pixelvalues'])\n",
        "res1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi-o6-OagtZf",
        "colab_type": "text"
      },
      "source": [
        "### CNN from scratch\n",
        "In this section you train a cnn from scratch to learn to classify the images into the right label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlXRWiwi8FHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model  =  Sequential()\n",
        "\n",
        "model.add(Convolution2D(16,(3,3),activation=\"relu\",padding=\"same\",input_shape=(32,32,3)))\n",
        "model.add(Convolution2D(16,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Convolution2D(32,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(Convolution2D(32,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(300))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7B65EQTg6vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, Y_train, \n",
        "                    batch_size=64,\n",
        "                    epochs=10, validation_data=(X_val, Y_val),verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aud3gKbNhT3b",
        "colab": {}
      },
      "source": [
        "# plot the development of the accuracy and loss during training\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,(1))\n",
        "plt.plot(history.history['accuracy'],linestyle='-.')\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(1,2,(2))\n",
        "plt.plot(history.history['loss'],linestyle='-.')\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RYco3ZFohT3r",
        "colab": {}
      },
      "source": [
        "acc=np.average(np.argmax(model.predict(X_test),axis=1)==np.argmax(Y_test,axis=1))\n",
        "res2 = pd.DataFrame(\n",
        "          {'Acc' : acc}, index=['cnn from scratch']\n",
        ")\n",
        "pd.concat([res1,res2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wIZH1xpehpOH"
      },
      "source": [
        "### CNN from scratch with Dropout\n",
        "In this section you train a cnn from scratch to learn to classify the images into the right label. This time you will use dropout layers in the classification part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QYD-TYOzhpOM",
        "colab": {}
      },
      "source": [
        "model  =  Sequential()\n",
        "\n",
        "model.add(Convolution2D(16,(3,3),activation=\"relu\",padding=\"same\",input_shape=(32,32,3)))\n",
        "model.add(Convolution2D(16,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Convolution2D(32,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(Convolution2D(32,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(500))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(300))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cfv_8EYChpOR",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, Y_train, \n",
        "                    batch_size=64,\n",
        "                    epochs=20, validation_data=(X_val, Y_val),verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4utU_Wd7hpOY",
        "colab": {}
      },
      "source": [
        "# plot the development of the accuracy and loss during training\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,(1))\n",
        "plt.plot(history.history['accuracy'],linestyle='-.')\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(1,2,(2))\n",
        "plt.plot(history.history['loss'],linestyle='-.')\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7qAipwYkhpOf",
        "colab": {}
      },
      "source": [
        "acc=np.average(np.argmax(model.predict(X_test),axis=1)==np.argmax(Y_test,axis=1))\n",
        "res3 = pd.DataFrame(\n",
        "          {'Acc' : acc}, index=['cnn from scratch with dropout']\n",
        ")\n",
        "pd.concat([res1,res2,res3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qP_oH_fcih0D"
      },
      "source": [
        "### CNN from scratch with Batchnorm\n",
        "In this section you train a cnn from scratch to learn to classify the images into the right label. This time you will use batchnorm on the input and in the convolutional part of the network. Note that we reload the original images and do not normalize them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zmabrMdGkTLx",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# separate train val and test dataset\n",
        "X_train_=x_train[0:10000] \n",
        "Y_train=to_categorical(y_train[0:10000],10) # one-hot encoding\n",
        "\n",
        "X_val_=x_train[20000:30000] \n",
        "Y_val=to_categorical(y_train[20000:30000],10)\n",
        "\n",
        "X_test_=x_test \n",
        "Y_test=to_categorical(y_test,10)\n",
        "\n",
        "del x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "print(X_train_.shape)\n",
        "print(X_val_.shape)\n",
        "print(X_test_.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RZCaUy0PkTL7",
        "colab": {}
      },
      "source": [
        "# not normalized, values between 0 and 255\n",
        "X_train_[0,0:10,0,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLQ-RZgxih0J",
        "colab": {}
      },
      "source": [
        "model  =  Sequential()\n",
        "\n",
        "model.add(BatchNormalization(input_shape=(32,32,3)))\n",
        "model.add(Convolution2D(16,(3,3),padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(16,(3,3),padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Convolution2D(32,(3,3),padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(32,(3,3),padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(300))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_f5HV12Pih0Q",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train_, Y_train, \n",
        "                    batch_size=64,\n",
        "                    epochs=10, validation_data=(X_val_, Y_val),verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ar8YM_44ih0Y",
        "colab": {}
      },
      "source": [
        "# plot the development of the accuracy and loss during training\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,(1))\n",
        "plt.plot(history.history['accuracy'],linestyle='-.')\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(1,2,(2))\n",
        "plt.plot(history.history['loss'],linestyle='-.')\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jgqm4Erdih0e",
        "colab": {}
      },
      "source": [
        "acc=np.average(np.argmax(model.predict(X_test_),axis=1)==np.argmax(Y_test,axis=1))\n",
        "res4 = pd.DataFrame(\n",
        "          {'Acc' : acc}, index=['cnn from scratch with batchnorm']\n",
        ")\n",
        "pd.concat([res1,res2,res3,res4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPx0Bs50ej4j",
        "colab_type": "text"
      },
      "source": [
        "### RF on VGG features\n",
        "In this section you use a pretrained vgg16 network that was trained on the imagenet data as a image feature extractor and then train a random forest on these features. You will extract a 512 dimensional vector from each image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vow2NgC719CZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False,input_shape=(32,32,3),pooling=\"avg\")\n",
        "base_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J61OHaDf19RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_vgg_features=base_model.predict(X_train)\n",
        "X_val_vgg_features=base_model.predict(X_val)\n",
        "X_test_vgg_features=base_model.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiZX32Dn19Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=40,random_state=22)\n",
        "clf.fit(X_train_vgg_features, np.argmax(Y_train,axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjVW19Dx19WE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=clf.predict(X_test_vgg_features)\n",
        "acc=np.average(pred==np.argmax(Y_test,axis=1))\n",
        "res5 = pd.DataFrame(\n",
        "          {'Acc' : acc}, index=['rf on vgg features']\n",
        ")\n",
        "pd.concat([res1,res2,res3,res4,res5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBNDnWh-fVDN",
        "colab_type": "text"
      },
      "source": [
        "### Transfer learning\n",
        "In this section you use a pretrained vgg16 network that was trained on the imagenet and keep the weights of the convolutional part fixed. You will add your own classification part on top of the imagetnet-learned convolutional part. Only the classification part will be learned, we fix all other weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNimnD7A39uU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False,input_shape=(32,32,3))\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(400, activation='relu')(x)\n",
        "x = Dense(200, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxG3Q7Wf39zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLp0Htz539r8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "for i, layer in enumerate(model.layers):\n",
        "   print(i, layer.name,layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F159Vo_E39o1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit(X_train, Y_train, \n",
        "                  batch_size=64, \n",
        "                  epochs=15,\n",
        "                  verbose=1,\n",
        "                  shuffle=True,\n",
        "                  validation_data=(X_val, Y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJssR3uU6I2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the development of the accuracy and loss during training\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,(1))\n",
        "plt.plot(history.history['accuracy'],linestyle='-.')\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(1,2,(2))\n",
        "plt.plot(history.history['loss'],linestyle='-.')\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rCQihzV189V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=np.average(np.argmax(model.predict(X_test),axis=1)==np.argmax(Y_test,axis=1))\n",
        "res6 = pd.DataFrame(\n",
        "          {'Acc' : acc}, index=['transfer learning on vgg features']\n",
        ")\n",
        "pd.concat([res1,res2,res3,res4,res5,res6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XiKVO-uOlMbg"
      },
      "source": [
        "### CNN from scratch with Data Augmentation\n",
        "In this section you train a cnn from scratch to learn to classify the images into the right label. This time you will use data augmentation, so the network will train on slightly different versions of the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WXFfkFM5lMbn",
        "colab": {}
      },
      "source": [
        "model  =  Sequential()\n",
        "\n",
        "model.add(Convolution2D(16,(3,3),activation=\"relu\",padding=\"same\",input_shape=(32,32,3)))\n",
        "model.add(Convolution2D(16,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Convolution2D(32,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(Convolution2D(32,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(300))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWzxK6id8FPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "fill_mode=\"constant\",\n",
        "cval=1,horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQD2VP7s8FMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=22\n",
        "data_aug=datagen.flow(x=X_train[i:(i+1)], y=Y_train[i:(i+1)], batch_size=1)\n",
        "plt.imshow(X_train[i])\n",
        "plt.show()\n",
        "plt.figure(figsize=(15,15))\n",
        "for i in range (0,25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  x_aug,y_aug=next(data_aug)\n",
        "  plt.imshow(x_aug[0,:,:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgSM-3XT8FE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=64), \n",
        "                              steps_per_epoch=len(X_train)/64, \n",
        "                              epochs=40, \n",
        "                              validation_data=(X_val, Y_val),\n",
        "                              verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19jPWWNeDBgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the development of the accuracy and loss during training\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,(1))\n",
        "plt.plot(history.history['accuracy'],linestyle='-.')\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(1,2,(2))\n",
        "plt.plot(history.history['loss'],linestyle='-.')\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUiqoT9gDafA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=np.average(np.argmax(model.predict(X_test),axis=1)==np.argmax(Y_test,axis=1))\n",
        "acc\n",
        "res7 = pd.DataFrame(\n",
        "          {'Acc' : acc}, index=['cnn from scratch with data augmentation']\n",
        ")\n",
        "pd.concat([res1,res2,res3,res4,res5,res6,res7])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWIwUCktrnE4",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise\n",
        "Try to beat the performace of the best network with your own neutal network.  \n",
        "*Hint: You might want to combine things from the neural networks above*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoTLI7sErojX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}