{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "06_cnn_mnist_shuffled_sol.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tbTYFRhJoaBu"
      },
      "source": [
        "# MNIST digit classification before and after shuffling\n",
        "\n",
        "\n",
        "In this notebook you will use a convolutional neural network (CNN), to train two neural networks on the original and the shuffled MNIST dataset and compare the performances.\n",
        "\n",
        "\n",
        "**Dataset:** You work with the MNIST dataset. We have 60'000 28x28 pixel greyscale images of digits and want to classify them into the right label (0-9).\n",
        "\n",
        "**Content:**\n",
        "* load the original MNIST data and create a randomly shuffled version of the data\n",
        "* visualize samples of the orginal and shuffled version of the data\n",
        "* use keras to train a CNN with the original and shuffled data and compare the perfomance on new unseen test data\n",
        "* check if the local structure of the pixels within the images have an impact on the classification performance when you use a CNN\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PEIS4WvpsT5t"
      },
      "source": [
        "#### Imports\n",
        "\n",
        "In the next two cells, we load all the required libraries and functions. We download the Mnist data, normalize the pixelvalues to be between 0 and 1, and seperate it into a training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y6S_hQX5oaBw",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# load required libraries:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('default')\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten , Activation\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras import optimizers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4sZ8lqFfoaB2",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# separate x_train in X_train and X_val, same for y_train\n",
        "X_train=x_train[0:50000] / 255 #divide by 255 so that they are in range 0 to 1\n",
        "Y_train=to_categorical(y_train[0:50000],10) # one-hot encoding\n",
        "\n",
        "X_val=x_train[50000:60000] / 255\n",
        "Y_val=to_categorical(y_train[50000:60000],10)\n",
        "\n",
        "X_test=x_test / 255\n",
        "Y_test=to_categorical(y_test,10)\n",
        "\n",
        "del x_train, y_train, x_test, y_test\n",
        "\n",
        "X_train=np.reshape(X_train, (X_train.shape[0],28,28,1))\n",
        "X_val=np.reshape(X_val, (X_val.shape[0],28,28,1))\n",
        "X_test=np.reshape(X_test, (X_test.shape[0],28,28,1))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3ly7CrHtLUP9"
      },
      "source": [
        "Let's visualize the first 4 mnist images before shuffling the pixels randomly around. It is very easy to recognise the true label of the digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c4gUgwGUeftF",
        "colab": {}
      },
      "source": [
        "# visualize the 4 first mnist images before shuffling the pixels\n",
        "plt.figure(figsize=(12,12))\n",
        "for i in range(0,4):\n",
        "    plt.subplot(1,4,(i+1))\n",
        "    plt.imshow((X_train[i,:,:,0]),cmap=\"gray\")\n",
        "    plt.title('true label: '+np.str(np.argmax(Y_train,axis=1)[i]))\n",
        "    #plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m6laMbqWLqlz"
      },
      "source": [
        "In the next cell we shuffle the pixel of each image randomly around. Note that we shuffle every image in same manner!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o744FOiN1S6y",
        "colab": {}
      },
      "source": [
        "# function to shuffle the pixel order within an image\n",
        "# used to shuffel the pixels of all mnist images in the same manner\n",
        "def shuffel_pixels(idx, data):\n",
        "  data_new=np.zeros((data.shape))\n",
        "  for i,img in enumerate(data):\n",
        "    data_new[i] = img.flatten()[idx].reshape((28,28,1))\n",
        "  return data_new\n",
        "\n",
        "np.random.seed(42)\n",
        "shuffel_idx = np.random.permutation(np.arange(28*28))\n",
        "X_train_shuffle = shuffel_pixels(shuffel_idx, X_train)\n",
        "X_val_shuffle = shuffel_pixels(shuffel_idx, X_val)\n",
        "X_test_shuffle = shuffel_pixels(shuffel_idx, X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VXK_HJbdMAeg"
      },
      "source": [
        "Let's visualize the first 4 mnist images after shuffling the pixels randomly around. Now as a human you have no chance to recognise the true label of the digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZrZk47bkoaB7",
        "colab": {}
      },
      "source": [
        "# visualize the 4 first mnist images after shuffling the pixels\n",
        "plt.figure(figsize=(12,12))\n",
        "for i in range(0,4):\n",
        "    plt.subplot(1,4,(i+1))\n",
        "    plt.imshow((X_train_shuffle[i,:,:,0]),cmap=\"gray\")\n",
        "    plt.title('true label: '+np.str(np.argmax(Y_train,axis=1)[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZaRFUEP8HJkq"
      },
      "source": [
        "# CNN as classification model for MNIST data\n",
        "\n",
        "Now, we train a CNN to classify the MNIST data. We use the same netwok architecture and train first with the original data and then with the shuffled data. \n",
        "* Use a CNN with 2 convolution blocks and 2 fully connected layers as classification model\n",
        "* train it once on the original train data and check the performance on the original test data\n",
        "* train it once on the shuffeled train data and check the performance on the accordingly shuffled test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cFJtO1FFHJkz"
      },
      "source": [
        "### Train the CNN on the original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iq45_Gs1HJk1",
        "colab": {}
      },
      "source": [
        "# check the shape of the orginal data\n",
        "# we need matrices as input\n",
        "X_train.shape,Y_train.shape,X_val.shape,Y_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fFBbAdLeTZuv"
      },
      "source": [
        "In the next cell we define the hyperparameters and architecture of the CNN. We use:\n",
        ">the relu activation function  \n",
        ">batchsize of 128  \n",
        ">kernelsize of 3x3  \n",
        ">poolingsize of 2x2   \n",
        ">our inputs are the greyscaled MNIST images, so the shape is 28x28x1  \n",
        "> we use 2 convolutional blocks with 8 filters and then a maxpooling layer followed by again 2 convolutional blocks with 16 filters and then a maxpooling  \n",
        "> then we flatten the output and use a fully connected layer with 40 nodes and the output has 10 nodes with the softmax activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSfYQ4f1KYVp",
        "colab": {}
      },
      "source": [
        "# here we define hyperparameter of the CNN\n",
        "batch_size = 128\n",
        "nb_classes = 10\n",
        "img_rows, img_cols = 28, 28\n",
        "kernel_size = (3, 3)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "pool_size = (2, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3xwh0iYrHJk_",
        "colab": {}
      },
      "source": [
        "# define CNN with 2 convolution blocks and 2 fully connected layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(8,kernel_size,padding='same',input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(8, kernel_size,padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=pool_size))\n",
        "\n",
        "##### Your code here ######\n",
        "##### add two convolutional layers with each 16 filter and a maxpooling layer  \n",
        "\n",
        "\n",
        "##### End of your code  ######\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(40))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# compile model and intitialize weights\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "blxHZguwHJlG",
        "colab": {}
      },
      "source": [
        "# summarize model along with number of model weights\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "430DSTDIHJlP",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "history=model.fit(X_train, Y_train, \n",
        "                  batch_size=128, \n",
        "                  epochs=10,\n",
        "                  verbose=1, \n",
        "                  validation_data=(X_val, Y_val)\n",
        "                 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q8GcmSWoHJlX",
        "colab": {}
      },
      "source": [
        "# plot the development of the accuracy and loss during training\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,(1))\n",
        "plt.plot(history.history['accuracy'],linestyle='-.')\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(1,2,(2))\n",
        "plt.plot(history.history['loss'],linestyle='-.')\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CAcwJRvDHJlf"
      },
      "source": [
        "#### Prediction on the test set after training on original data\n",
        "\n",
        "Now, let's use CNN that was trained on the original data to predict new unseen data (our testdata). We determine the confusion matrix and the accuracy on the testdata to evaluate the classification performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AdB-5bEjHJlh",
        "colab": {}
      },
      "source": [
        "#### Exercise\n",
        "#### Use the trained model to calculate the accuracy and the confusion matrix on the test data\n",
        "\n",
        "### Your code here ###\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eXWJXLO5HJll"
      },
      "source": [
        "### Train the CNN on the shuffled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n43wXtMuHJln",
        "colab": {}
      },
      "source": [
        "# check the shape of the shuffled data\n",
        "# we need matrices as input\n",
        "X_train_shuffle.shape,Y_train.shape,X_val_shuffle.shape,Y_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9uHoZFjHHJlt",
        "colab": {}
      },
      "source": [
        "# define CNN with 2 convolution blocks and 2 fully connected layers  \n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(8,kernel_size,padding='same',input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(8, kernel_size,padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=pool_size))\n",
        "\n",
        "model.add(Convolution2D(16, kernel_size,padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(16,kernel_size,padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=pool_size))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(40))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# compile model and intitialize weights\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SEQBad6jHJly",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "history=model.fit(X_train_shuffle, Y_train, \n",
        "                  batch_size=128, \n",
        "                  epochs=10,\n",
        "                  verbose=1, \n",
        "                  validation_data=(X_val_shuffle, Y_val)\n",
        "                 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_O6iw7xJHJmA",
        "colab": {}
      },
      "source": [
        "# plot the development of the accuracy and loss during training\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,(1))\n",
        "plt.plot(history.history['accuracy'],linestyle='-.')\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(1,2,(2))\n",
        "plt.plot(history.history['loss'],linestyle='-.')\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fz2TmqDyHJmF"
      },
      "source": [
        "#### Prediction on the test set after training on the shuffled data\n",
        "\n",
        "Use the CNN that was trained on the shuffled data to predict new unseen data (our testdata). We determine the confusion matrix and the accuracy on the testdata to evaluate the classification performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeqB8PSuzlLT",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "Use the trained model to calculate the accuracy  and the confusion matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XPT49d5THJmJ",
        "colab": {}
      },
      "source": [
        "#### Exercise\n",
        "#### Use the trained model to calculate the accuracy and the confusion matrix on the shuffled test data\n",
        "\n",
        "### Your code here ###\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wv898fZgjb-Z"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "Compre the performances of the fcNN on the MNIST dataset to the CNN performances.  \n",
        "What do you observe?  \n",
        "Compre the performance of the CNN on the original and on the shuffled dataset.  \n",
        "Try to explain the differences.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6qUgfXcshaZY",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}