{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4K8Ug6ICkRtQ"
   },
   "source": [
    "# A simple CNN for the edge lover task\n",
    "\n",
    "In this notebook you train a very simple CNN with only 1 kernel to discriminate images containing vertical from those containing horizontal stripes. To check what pattern is recognized by the learned kernel you will visualize the weights of the kernel as an image. You will see that the CNN leans a useful kernel (either a vertical or horiziontal bar).You can experiment with the code to check the influence of the kernel size, the activation function and the pooling method on the result.  \n",
    "\n",
    "\n",
    "**Dataset:** You work with an artficially generatet dataset of greyscale images (50x50 pixel) with 10 vertical or horizontal bars. We want to classify them into whether or not an art lover will like them(0 or 1).  \n",
    "\n",
    "\n",
    "The idea of the notebook is that you try to understand the provided code by running it, checking the output and playing with it by slightly changing the code and rerunning it.  \n",
    "\n",
    "**Content:**\n",
    "* definig and generating the dataset X_train and X_val\n",
    "* visualize samples of the generated images\n",
    "* use keras to train a CNN with only one kernel (5x5 pixel)\n",
    "* visualize the weights of the leaned kernel and interpret if it is useful\n",
    "* repeat the last two steps to check if the learned kernel is always the same\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiB8bJNYn8oP"
   },
   "source": [
    "#### Imports and image generator functions\n",
    "\n",
    "In the next two cells, we load all the required libraries and functions. We define two functions to generate images with vertical and horizontal images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PDLAWRQ7iUB"
   },
   "outputs": [],
   "source": [
    "# load required libraries:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "import tensorflow.keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten , Activation\n",
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oq0FNqcBpj23"
   },
   "source": [
    "### Defining functions to generate images \n",
    "\n",
    "Here we define the function to genere images with vertical and horizontal bars, the arguments of the functions are the size of the image and the nr of bars you want to have. The bars are at random positions in the image with a random length. The image is black and white, meaning we have only two values for the pixels, 0 for black and 255 for white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqVBlR8yAO9c"
   },
   "outputs": [],
   "source": [
    "#define function to generate image with shape (size, size, 1) with stripes\n",
    "def generate_image_with_bars(size, bar_nr, vertical = True):\n",
    "  img=np.zeros((size,size,1),dtype=\"uint8\")\n",
    "  for i in range(0,bar_nr):\n",
    "    x,y = np.random.randint(0,size,2)\n",
    "    l  = np.int(np.random.randint(y,size,1))\n",
    "    if (vertical):\n",
    "      img[y:l,x,0]=255\n",
    "    else:\n",
    "      img[x,y:l,0]=255\n",
    "  return img  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUmdGzQLdqzB"
   },
   "source": [
    "Let's have a look how the generated images. We choose a size of 50x50 pixels and set the nr of bars in the image to 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "EccLz0FlXGuU",
    "outputId": "0514b883-36de-4df4-a6af-fb8b3ed47759"
   },
   "outputs": [],
   "source": [
    "# have a look on two generated images\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "img=generate_image_with_bars(50,10, vertical=True)\n",
    "plt.imshow(img[:,:,0],cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "img=generate_image_with_bars(50,10, vertical=False)\n",
    "plt.imshow(img[:,:,0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8gSwmyaevTk"
   },
   "source": [
    "### Make a train and validation dataset of images with vertical and horizontal images\n",
    "Now, let's make a train dataset *X_train* with 1000 images (500 images with vertical and 500 images with horizontal bars). We normalize the images values to be between 0 and 1 by dividing all values with 255. We create a secont dataste *X_val* with exactly the same properties to validate the training of the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "63omuptEILKu",
    "outputId": "117892ab-5c52-4063-9e55-d38b3182d1b9"
   },
   "outputs": [],
   "source": [
    "pixel=50  # define height and width of images\n",
    "num_images_train = 1000 #Number of training examples (divisible by 2) \n",
    "num_images_val = 1000 #Number of training examples (divisible by 2) \n",
    "\n",
    "# generate training data with vertical edges\n",
    "X_train =np.zeros((num_images_train,pixel,pixel,1))\n",
    "for i in range(0, num_images_train//2):\n",
    "   X_train[i]=generate_image_with_bars(pixel,10)\n",
    "# ... with horizontal\n",
    "for i in range(num_images_train//2, num_images_train):\n",
    "   X_train[i]=generate_image_with_bars(pixel,10, vertical=False)\n",
    "\n",
    "# generate validation data \n",
    "X_val =np.zeros((num_images_train,pixel,pixel,1))\n",
    "for i in range(0, num_images_train//2): \n",
    "   X_val[i]=generate_image_with_bars(pixel,10)\n",
    "# ... with horizontal\n",
    "for i in range(num_images_train//2, num_images_train):\n",
    "   X_val[i]=generate_image_with_bars(pixel,10, vertical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "63omuptEILKu",
    "outputId": "117892ab-5c52-4063-9e55-d38b3182d1b9"
   },
   "outputs": [],
   "source": [
    "# normalize the data to be between 0 and 1\n",
    "X_train=X_train/255\n",
    "X_val=X_val/255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajNnUoYyi7IQ"
   },
   "source": [
    "Here we make the labels for the art lover, 0 means he likes the image and 1 means that he doesn't like it. We convert the labels into the one hot encoding becuase we want to use two outputs in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41-L5hM8S_ZP"
   },
   "outputs": [],
   "source": [
    "# create class labels\n",
    "y = np.array([[0],[1]])\n",
    "Y_train = np.repeat(y, num_images_train //2)\n",
    "Y_val = np.repeat(y, num_images_train //2)\n",
    "\n",
    "# one-hot-encoding\n",
    "Y_train=to_categorical(Y_train,2)\n",
    "Y_val=to_categorical(Y_val,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZpr0h-VvatF"
   },
   "source": [
    "## Defining the CNN to predict which images the art lover likes\n",
    "\n",
    "Here we define the kind of special architecture of the CNN: \n",
    "\n",
    ">we use only one kernel with a size of 5x5 pixels  \n",
    ">then we apply a linar activation function  \n",
    ">the maxpooling layer takes the maximum of the whole activation map to predict the probability (output layer with softmax) if the art lover will like the image\n",
    "\n",
    "as loss we use the categorical_crossentropy and we train the model with a batchsize of 64 images per update.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Dfg1h2rUifd"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(1,(5,5),padding='same',input_shape=(pixel,pixel,1)))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "# take the max over all values in the activation map\n",
    "model.add(MaxPooling2D(pool_size=(pixel,pixel)))\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile model and initialize weights\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "r6eqV0TRU0_n",
    "outputId": "57a410b6-b7b2-4626-b1cf-e5239a3f1ece"
   },
   "outputs": [],
   "source": [
    "# let's summarize the CNN architectures along with the number of model weights\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Sc-BYd8kVCx0",
    "outputId": "f2256b2a-876c-400e-e4e0-171c11776124",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "history=model.fit(X_train, Y_train,\n",
    "                  validation_data=(X_val,Y_val),\n",
    "                  batch_size=64, \n",
    "                  epochs=50,\n",
    "                  verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "fK_AAAoiQtlc",
    "outputId": "dc0bd3f4-af0f-486f-ccd1-fcaf0e155506"
   },
   "outputs": [],
   "source": [
    "# plot the development of the accuracy and loss during training\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,(1))\n",
    "plt.plot(history.history['accuracy'],linestyle='-.')\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,(2))\n",
    "plt.plot(history.history['loss'],linestyle='-.')\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uOwR3Esbw8eN"
   },
   "source": [
    "### Visualize the learned kernel and experiment with the code\n",
    "\n",
    "You see that the CNN performs very good at this task (100% accuracy). We can check which pattern is recognized by the learned kernel and see if you think that this is helpful to distinguish between images with horizontal and vertical edges. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "colab_type": "code",
    "id": "pl1yuAddVRnE",
    "outputId": "deb5a73c-b238-4c4b-840f-885984dd278b"
   },
   "outputs": [],
   "source": [
    "# get the leared weights and display them as image\n",
    "conv_filter=model.get_weights()[0]\n",
    "print(conv_filter.shape)\n",
    "conv_filter=np.squeeze(conv_filter, axis=2)\n",
    "plt.imshow(conv_filter[:,:,0],\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U4gnnlAPp_Q2"
   },
   "source": [
    "#### Repeat the training and exerpiment with the kernelsize and activation function.\n",
    "\n",
    "*Exercise: Repeat the compiling and training for several times and check if the CNN always learns the same kernel.  \n",
    "You can experiment with the code and check what happens if you use another kernel size, activation function (relu instead of linear ) or pooling method AveragePooling instead of MaxPooling.  \n",
    "Try to make a prediction before doing the experiment.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRlCUwpVoy69"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nb_ch02_03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
